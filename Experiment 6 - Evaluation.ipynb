{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "This notebook selects data to evaluate the use of HW for linking. It is mainly used for selecting image pairs for annotation.\n",
    "\n",
    "We aim to evaluate\n",
    "- multimodality (linking by image, text or both)\n",
    "- model fine-tuning (fine-tuned models vs original siglip)\n",
    "\n",
    "We ask people to annotate n image pairs\n",
    "- for each multimodal search strategy we select records pairs using the following criteria:\n",
    "    - Linked by all models\n",
    "    - Linked only by the fine-tuned models\n",
    "    - Linked only by siglip\n",
    "    - Not linked\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from weavingtools.annotation_tools import *\n",
    "from weavingtools.annotation_tools import plot_by_record, open_image\n",
    "from weavingtools.linkage_tools import *\n",
    "from weavingtools.embedding_tools import *\n",
    "import scipy.spatial as sp\n",
    "import ipyannotations.generic\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_db = load_db(\"hw-16-08\",'heritage-weaver-base','google/siglip-base-patch16-224')\n",
    "collection_db_ft = load_db(\"hw-16-08\",'heritage-weaver-ft','Kaspar/siglip-heritage-weaver-text-last')\n",
    "collection_db_ft_best = load_db(\"hw-16-08\",'heritage-weaver-ft-best','Kaspar/siglip-heritage-weaver-text-best')\n",
    "collection_df = pd.read_csv('data/heritage_weaver_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107222, 107222, 107222)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_db.count(),collection_db_ft.count(),collection_db_ft_best.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotator = 'NK'\n",
    "coll1, coll2 = 'smg','nms'\n",
    "percentile = 99.0 \n",
    "#randomize = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.7563818202361199 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n",
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.7661070561655263 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n",
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.8216554902540544 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n"
     ]
    }
   ],
   "source": [
    "edges_img_sigl, _, _ = get_edges(collection_db,coll1,coll2, 'image','image', 'max',percentile )\n",
    "edges_img_sigl_ft, _, _ = get_edges(collection_db_ft,coll1,coll2, 'image','image', 'max',percentile )\n",
    "edges_img_sigl_ft_best, _, _ = get_edges(collection_db_ft_best,coll1,coll2, 'image','image', 'max',percentile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agreement between the three methods\n",
    "img_common_links = set(edges_img_sigl).intersection(edges_img_sigl_ft,edges_img_sigl_ft_best)\n",
    "# only in siglip not an edge returned by fine-tuned models\n",
    "img_only_siglip = set(edges_img_sigl).difference(edges_img_sigl_ft,edges_img_sigl_ft_best)\n",
    "# agreement among fine-tuned models but not by siglip\n",
    "img_agreement_only_ft = set(edges_img_sigl_ft).intersection(edges_img_sigl_ft_best).difference(edges_img_sigl)\n",
    "# only siglip ft \n",
    "only_siglip_ft = set(edges_img_sigl_ft).difference(edges_img_sigl_ft_best,edges_img_sigl)\n",
    "# only siglip ft best\n",
    "img_only_siglip_ft_best = set(edges_img_sigl_ft_best).difference(edges_img_sigl_ft,edges_img_sigl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.7896803665751463 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n",
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.8599656041694197 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n",
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.8868009537004167 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n"
     ]
    }
   ],
   "source": [
    "edges_txt_sigl, _, _ = get_edges(collection_db,coll1,coll2, 'text','text', 'mean',percentile )\n",
    "edges_txt_sigl_ft, _, _ = get_edges(collection_db_ft,coll1,coll2, 'text','text', 'mean',percentile )\n",
    "edges_txt_sigl_ft_best, _, _ = get_edges(collection_db_ft_best,coll1,coll2, 'text','text', 'mean',percentile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agreement between the three methods\n",
    "txt_common_links = set(edges_txt_sigl).intersection(edges_txt_sigl_ft,edges_txt_sigl_ft_best)\n",
    "# only in siglip not an edge returned by fine-tuned models\n",
    "txt_only_siglip = set(edges_txt_sigl).difference(edges_txt_sigl_ft,edges_txt_sigl_ft_best)\n",
    "# agreement among fine-tuned models but not by siglip\n",
    "txt_agreement_only_ft = set(edges_txt_sigl_ft).intersection(edges_txt_sigl_ft_best).difference(edges_txt_sigl)\n",
    "# only siglip ft \n",
    "txt_only_siglip_ft = set(edges_txt_sigl_ft).difference(edges_txt_sigl_ft_best,edges_txt_sigl)\n",
    "# only siglip ft best\n",
    "txt_only_siglip_ft_best = set(edges_txt_sigl_ft_best).difference(edges_txt_sigl_ft,edges_txt_sigl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.09570732179132528 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n",
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.09827218164253193 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n",
      "Get inputs...\n",
      "Compute similarities...\n",
      "--- Get similarities ---\n",
      "--- Using 0.10449278490318314 as threshold ---\n",
      "--- Aggregate similarities by record ---\n",
      "--- Threshold similarities and binarize ---\n",
      "Retrieve edges...\n"
     ]
    }
   ],
   "source": [
    "edges_txt_img_sigl, _, _ = get_edges(collection_db,coll1,coll2, 'text','image', 'max',percentile )\n",
    "edges_txt_img_sigl_ft, _, _ = get_edges(collection_db_ft,coll1,coll2, 'text','image', 'max',percentile )\n",
    "edges_txt_img_sigl_ft_best, _, _ = get_edges(collection_db_ft_best,coll1,coll2, 'text','image', 'max',percentile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agreement between the three methods\n",
    "txt_img_common_links = set(edges_txt_img_sigl).intersection(edges_txt_img_sigl_ft,edges_txt_img_sigl_ft_best)\n",
    "# only in siglip not an edge returned by fine-tuned models\n",
    "txt_img_only_siglip = set(edges_txt_img_sigl).difference(edges_txt_img_sigl_ft,edges_txt_img_sigl_ft_best)\n",
    "# agreement among fine-tuned models but not by siglip\n",
    "txt_img_agreement_only_ft = set(edges_txt_img_sigl_ft).intersection(edges_txt_img_sigl_ft_best).difference(edges_txt_img_sigl)\n",
    "# only siglip ft \n",
    "txt_img_only_siglip_ft = set(edges_txt_img_sigl_ft).difference(edges_txt_img_sigl_ft_best,edges_txt_img_sigl)\n",
    "# only siglip ft best\n",
    "txt_img_only_siglip_ft_best = set(edges_txt_img_sigl_ft_best).difference(edges_txt_img_sigl_ft,edges_txt_img_sigl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # agreement between the three methods\n",
    "# mult_common_links = set(txt_common_links).intersection(img_common_links)\n",
    "# # only in siglip not an edge returned by fine-tuned models\n",
    "# mult_only_siglip = set(txt_only_siglip).intersection(img_only_siglip)\n",
    "# # agreement among fine-tuned models but not by siglip\n",
    "# mult_agreement_only_ft = set(txt_agreement_only_ft).intersection(img_agreement_only_ft)\n",
    "# # only siglip ft \n",
    "# mult_only_siglip_ft = set(txt_only_siglip_ft).intersection(only_siglip_ft)\n",
    "# # only siglip ft text\n",
    "# mult_only_siglip_ft_text = set(txt_only_siglip_ft_text).intersection(oimg_nly_siglip_ft_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = [\n",
    "   ('img_common_links', img_common_links), \n",
    "    ('img_only_siglip', img_only_siglip), \n",
    "    ('img_agreement_only_ft', img_agreement_only_ft), \n",
    "    ('only_siglip_ft', only_siglip_ft), \n",
    "    ('img_only_siglip_ft_text', img_only_siglip_ft_best),\n",
    "    ('txt_common_links', txt_common_links), \n",
    "    ('txt_only_siglip', txt_only_siglip), \n",
    "    ('txt_agreement_only_ft', txt_agreement_only_ft), \n",
    "    ('txt_only_siglip_ft', txt_only_siglip_ft), \n",
    "    ('txt_only_siglip_ft_text', txt_only_siglip_ft_best),\n",
    "    ('txt_img_common_links', txt_img_common_links), \n",
    "    ('txt_img_only_siglip', txt_img_only_siglip), \n",
    "    ('txt_img_agreement_only_ft', txt_img_agreement_only_ft), \n",
    "    ('txt_img_only_siglip_ft', txt_img_only_siglip_ft), \n",
    "    ('txt_img_only_siglip_ft_text', txt_img_only_siglip_ft_best),\n",
    "    # ('mult_common_links', mult_common_links), \n",
    "    # ('mult_only_siglip', mult_only_siglip), \n",
    "    # ('mult_agreement_only_ft', mult_agreement_only_ft), \n",
    "    # ('mult_only_siglip_ft', mult_only_siglip_ft), \n",
    "    # ('mult_only_siglip_ft_text', mult_only_siglip_ft_text)\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export links and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 3)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator = 'GrG'\n",
    "\n",
    "from random import shuffle\n",
    "to_annotate = []\n",
    "top_n = 7\n",
    "for name, links in all_links:\n",
    "    links = list(links)\n",
    "    random.shuffle(links)\n",
    "    to_annotate.extend([(name, *link) for link in links[:top_n]])\n",
    "\n",
    "df_annotation = pd.DataFrame(to_annotate, columns=['link_type','source','target'])\n",
    "df_annotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 13)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs = collection_df[['record_id','img_url','img_path','description','name']].drop_duplicates().reset_index(drop=True)\n",
    "df_annotation_with_img = df_annotation.merge(\n",
    "    df_imgs, \n",
    "    left_on='source', right_on='record_id', how='left'\n",
    "        ).merge(df_imgs, left_on='target', right_on='record_id', how='left', suffixes=('_source','_target'))\n",
    "df_annotation_with_img.drop_duplicates(subset=['source','target'], inplace=True)\n",
    "df_annotation_with_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotation_with_img.to_csv('data/heritage_weaver_annotations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_pair_image(record_description_pair):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7.5))\n",
    "    \n",
    "    for i,pair in enumerate(record_description_pair):\n",
    "        #i+=1\n",
    "        img_path = pair[0]\n",
    "        description = soft_wrap_text(pair[1][:200])\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img.thumbnail((224, 224))\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(description, fontsize = 18)\n",
    "        axes[i].axis('off')\n",
    "         \n",
    "    #plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotation_with_img = df_annotation_with_img.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_source = list(df_annotation_with_img[['img_path_source','description_source']].values)\n",
    "image_target = list(df_annotation_with_img[['img_path_target','description_target']].values)\n",
    "image_pairs = list(zip(image_source, image_target))\n",
    "len(image_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [[i,record_pair_image(p)] for i,p in enumerate(image_pairs[:3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data).to_excel('data/heritage_weaver_annotations.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "def save_images_for_annoation(image_pairs, output_path):\n",
    " \n",
    "    \"\"\"\n",
    "    Save a DataFrame to Excel with matplotlib-generated images in specific cells.\n",
    "    \n",
    "    Parameters:\n",
    "    - image pairs:\n",
    "    - output: Output image.\n",
    "    \"\"\"\n",
    "    #df = pd.DataFrame()\n",
    "    # Create a Pandas Excel writer object using XlsxWriter as the engine\n",
    "    #with pd.ExcelWriter(output_excel, engine='xlsxwriter') as writer:\n",
    "        # Convert the DataFrame to an Excel object\n",
    "    output_path = Path(output_path)\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "    for idx, img_pair in enumerate(image_pairs):\n",
    "            # Create a BytesIO object to hold the image data in memory\n",
    "            #image_data = BytesIO()\n",
    "\n",
    "            # Generate the matplotlib figure and save it to the BytesIO object\n",
    "            fig = record_pair_image(img_pair)  # Assume the function generates and returns a figure\n",
    "            fig.savefig(output_path / f'{idx}.jpg', format='jpg')\n",
    "            plt.close(fig)  # Close the figure to free up memory\n",
    "\n",
    "            # Seek to the beginning of the BytesIO object so it can be read from\n",
    "    print('done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Output Excel file path\n",
    "output = f'data/linkage_annotations_{annotator}'\n",
    "\n",
    "# Save DataFrame with matplotlib-generated images\n",
    "save_images_for_annoation(image_pairs, output)\n",
    "df_annotation_with_img.to_csv(f'{output}/{annotator}_metdata.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heritageweaver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
